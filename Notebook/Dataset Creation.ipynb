{"cells":[{"cell_type":"markdown","source":["# Enhanced AI Engineer Assignment - Domain Name Generator\n","\n","First of all, thank you for the opportunity to work on this assignment and potentially join your team.\n","\n","Before diving into the technical details, I’d like to briefly share my initial thoughts. In my opinion, this task could be easily handled using prompt engineering alone. For example, a simple system prompt like: *“You are a domain name generator. Given a business description, suggest 3 relevant, memorable domain names. Format: domain1.com, domain2.net, domain3.org”*\n","\n","would likely work very well with GPT-4, Claude, or even smaller models like GPT-3.5.\n","\n","Of course, I understand that the real goal behind this assignment is not just to generate domain names which is a relatively simple task, but to evaluate engineering and machine learning skills more broadly.\n","\n","\n","\n","\n"],"metadata":{"id":"auiNb5LxCtF3"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49773,"status":"ok","timestamp":1754312284931,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"},"user_tz":-60},"id":"GdFaPmMisLc7","outputId":"4c983fe0-4d7b-49d5-ccea-c9396d532765"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"UEi9MSppnEKz"},"source":["## Creation of the Dataset\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":["\n","In this section, we simulate realistic business descriptions and domain names using structured templates and random sampling.\n","Each data sample contains:\n","\n","A business description (e.g., \"best clothing store in city\")\n","\n","A list of 3 domain name suggestions generated using predefined patterns (e.g., theclothingstorespot.com, clothingstorecity.net, etc.)\n","\n","We use a mix of business types, locations, adjectives, and domain patterns to ensure diversity in the dataset. The goal is to create a rich and varied training set that can later be used to fine-tune or evaluate an open-source language model.\n","\n","Of course, this is not the most sophisticated dataset — the domain names are pattern-based and somewhat formulaic — but it's good enough for testing technical ideas and building the rest of the evaluation pipeline."],"metadata":{"id":"niZSXG9-DlnI"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72,"status":"ok","timestamp":1754069731195,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"},"user_tz":-60},"id":"ohu3xq38iCGe","outputId":"1941e475-7509-4987-a592-d88bf608af8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated 1000 examples with realistic domain suggestions.\n"]}],"source":["import pandas as pd\n","import json\n","import random\n","\n","\n","business_groups = {\n","    \"food\": [\"restaurant\", \"coffee shop\", \"bakery\", \"food truck\"],\n","    \"tech\": [\"tech startup\", \"AI solution agency\"],\n","    \"professional\": [\"consulting firm\", \"law firm\", \"dental clinic\"],\n","    \"wellness\": [\"fitness gym\", \"yoga studio\", \"spa\", \"hair salon\"],\n","    \"retail\": [\"clothing store\", \"bookstore\", \"pet store\"],\n","    \"creative\": [\"photography studio\"]\n","}\n","\n","group_adjectives = {\n","    \"food\": [\"best\", \"premium\", \"downtown\"],\n","    \"tech\": [\"expert\", \"professional\", \"innovative\"],\n","    \"professional\": [\"expert\", \"trusted\", \"professional\"],\n","    \"wellness\": [\"premium\", \"best\", \"quality\"],\n","    \"retail\": [\"best\", \"trendy\"],\n","    \"creative\": [\"creative\", \"expert\"]\n","}\n","\n","group_patterns = {\n","    \"food\": [\"best{business_type}\", \"{business_type}{location}\", \"the{business_type}spot\"],\n","    \"tech\": [\"{adjective}{business_type}\", \"{business_type}pro\", \"{business_type}{location}\"],\n","    \"professional\": [\"{adjective}{business_type}\", \"{business_type}pro\",\"{business_type}{location}\"],\n","    \"wellness\": [\"{adjective}{business_type}\", \"best{business_type}\", \"{business_type}pro\"],\n","    \"retail\": [\"best{business_type}\", \"{business_type}{location}\", \"the{business_type}spot\"],\n","    \"creative\": [\"the{business_type}spot\", \"{adjective}{business_type}\", \"{business_type}{location}\"]\n","}\n","\n","def get_group(business):\n","    for group, types in business_groups.items():\n","        if business in types:\n","            return group\n","    return \"general\"\n","\n","# Generate the synthetic dataset\n","def generate_synthetic_data(num_samples=1000):\n","    data = []\n","    all_businesses = sum(business_groups.values(), [])\n","\n","    for _ in range(num_samples):\n","        business = random.choice(all_businesses)\n","        group = get_group(business)\n","\n","        location = random.choice([\"downtown\", \"city\", \"local\", \"neighborhood\"])\n","        adjective = random.choice(group_adjectives[group])\n","        description = f\"{adjective} {business} in {location}\"\n","\n","        # Generate domain\n","        domains = []\n","        used_patterns = set()\n","        patterns_pool = group_patterns[group]\n","\n","        while len(domains) < 3 and len(used_patterns) < len(patterns_pool):\n","            pattern = random.choice(patterns_pool)\n","            if pattern in used_patterns:\n","                continue\n","            used_patterns.add(pattern)\n","\n","            domain_name = pattern.format(\n","                business_type=business.replace(\" \", \"\"),\n","                location=location,\n","                adjective=adjective\n","            )\n","            extension = random.choice([\".com\", \".net\", \".org\", \".io\"])\n","            domains.append(domain_name.lower() + extension)\n","\n","        data.append({\n","            \"business_description\": description,\n","            \"domain_suggestions\": domains\n","        })\n","\n","    return data\n","\n","# Create and save the dataset\n","dataset = generate_synthetic_data(1000)\n","df = pd.DataFrame(dataset)\n","df.to_json(\"/content/drive/MyDrive/FamilyWall/Data/synthetic_dataset.json\", orient=\"records\", indent=2)\n","print(f\"Generated {len(dataset)} examples with realistic domain suggestions.\")"]},{"cell_type":"markdown","metadata":{"id":"eHOdWLvgnrqn"},"source":["## DistilGPT2 + LoRA"]},{"cell_type":"markdown","source":["1. Why GPT2?\n","\n","Lightweight and fast for experimentation\n","Good text generation capabilities\n","Well-supported by transformers library\n","\n","2. Why LoRA?\n","\n","Parameter-efficient fine-tuning (only ~1% of parameters updated)\n","Faster training and lower memory requirements\n","Easy to swap adapters for different model versions\n","\n","\n","\n","NB: I’m using the free plan of Google Colab, so I’m limited in terms of compute and runtime"],"metadata":{"id":"54AQ1JvNDgGy"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":107227,"status":"ok","timestamp":1754312453779,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"},"user_tz":-60},"id":"vFklU7YMoFl4","outputId":"e193ef3c-f5d1-4c64-ade3-c7be0c3e20fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.9.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n","Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m124.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed bitsandbytes-0.46.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n","Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.34.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.14)\n"]}],"source":["!pip install transformers datasets peft bitsandbytes\n","!pip install accelerate\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"tSvbfxTZtsd6","executionInfo":{"status":"ok","timestamp":1754312495730,"user_tz":-60,"elapsed":41949,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"}}},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n","from peft import get_peft_model, LoraConfig, TaskType\n","from datasets import Dataset\n","import pandas as pd\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":530,"referenced_widgets":["c083c973ab8f464e91eaa09c7089eaba","a697ee7252664ee38f576cfbeab8a4c1","46aef43bd83a492190938a7694498e68","292d00d84ebb49fe95c9ba08c49a7dd5","ecd7badd6fe849ca9ef90b96e32c3029","2099d052991c4292aa21853f7c889021","6a9ffceaf8bb4f51aa5028ec417c3589","3bf41f7b2a6340c09ac378cc2dda207b","90150b961611467881f79bf0b2099fb7","c4a88d32f55c4d1f82a7118ebe0b7c35","07675c070d134e0580c6abe22cbc55b9"]},"id":"zeYzEEsqrjdW","outputId":"8053dfeb-99e0-40ff-e3e4-c02b3070561d","executionInfo":{"status":"ok","timestamp":1754313481013,"user_tz":-60,"elapsed":412244,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1803: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c083c973ab8f464e91eaa09c7089eaba"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-239591968.py:59: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10000/10000 06:49, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.417500</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.398800</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.302600</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.257400</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.230500</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.212900</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.201700</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.193200</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.189900</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.187200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["import json\n","\n","with open(\"/content/drive/MyDrive/FamilyWall/Data/synthetic_dataset.json\", \"r\") as f:\n","  json_data = json.load(f)\n","\n","examples = []\n","for row in json_data:\n","    prompt = f\"Generate domain names for: {row['business_description']}\\nDomains:\"\n","    response = \", \".join(row['domain_suggestions'])\n","    examples.append({\"text\": f\"{prompt} {response}\"})\n","\n","dataset = Dataset.from_pandas(pd.DataFrame(examples))\n","\n","\n","def setup_gpt2_small_lora():\n","    model_name = \"gpt2\"\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_name,\n","        torch_dtype=torch.float16,\n","        device_map=\"auto\"\n","    )\n","    if tokenizer.pad_token is None:\n","        tokenizer.pad_token = tokenizer.eos_token\n","    lora_config = LoraConfig(\n","        task_type=TaskType.CAUSAL_LM,\n","        r=4,\n","        lora_alpha=16,\n","        lora_dropout=0.1,\n","        target_modules=[\"c_attn\"],\n","        bias=\"none\"\n","    )\n","    model = get_peft_model(model, lora_config)\n","    return model, tokenizer\n","\n","model, tokenizer = setup_gpt2_small_lora()\n","\n","def tokenize_function(examples):\n","    tokens = tokenizer(\n","        examples[\"text\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=128,\n","    )\n","    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n","    return tokens\n","\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/FamilyWall/Model/gpt2-lora-domain-generator\",\n","    per_device_train_batch_size=1,\n","    num_train_epochs=10,\n","    logging_steps=1000,\n","    save_total_limit=1,\n","    report_to=\"none\"\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset,\n","    tokenizer=tokenizer\n",")\n","\n","trainer.train()\n","\n","#Save\n","trainer.save_model(\"/content/drive/MyDrive/FamilyWall/gpt2-lora-domain-generator\")"]},{"cell_type":"markdown","source":["## Test"],"metadata":{"id":"b0fm660ZcYFY"}},{"cell_type":"code","source":["from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n","from peft import PeftModel, PeftConfig\n","\n","# Load tokenizer + base model + LoRA weights\n","peft_model_dir = \"/content/drive/MyDrive/FamilyWall/gpt2-lora-domain-generator\"\n","base_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","model = PeftModel.from_pretrained(base_model, peft_model_dir)\n","\n","# Set padding token (important for GPT2)\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","# Build pipeline\n","pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n","\n","\n"],"metadata":{"id":"xGTxFYwPceOH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754240164068,"user_tz":-60,"elapsed":2536,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"}},"outputId":"e1c7567a-cf30-4f18-ff2c-96df8bf28417"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]}]},{"cell_type":"code","source":["# Try a prompt\n","prompt = \"Generate domain names for: delicious food Truck in downtown\\nDomains:\"\n","outputs = pipe(prompt, max_new_tokens=30, num_return_sequences=1, do_sample=True)\n","\n","print(outputs[0][\"generated_text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iDdw-UuFdG1F","executionInfo":{"status":"ok","timestamp":1754240174775,"user_tz":-60,"elapsed":1808,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"}},"outputId":"4f2e9a21-d315-48c0-93c2-b65b0f62b373"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Generate domain names for: delicious food Truck in downtown\n","Domains: foodtruckdowntown.org, bestfoodtruck.com, foodtruckdowntown.org\n"]}]},{"cell_type":"markdown","source":["## LLM Judge"],"metadata":{"id":"ULZQ9L08d3BV"}},{"cell_type":"code","source":["!pip install requests\n","!pip install huggingface_hub\n","\n"],"metadata":{"id":"COK6E3crd6cm","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ[\"HF_TOKEN\"] = \"\" # add you hugging face token\n"],"metadata":{"id":"S1TQyYd6yW5J","executionInfo":{"status":"ok","timestamp":1754235828677,"user_tz":-60,"elapsed":7,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from huggingface_hub import InferenceClient\n","import json\n","import re\n","\n","\n","\n","client = InferenceClient(model=\"Qwen/Qwen2.5-7B-Instruct\")\n","\n","\n","def generate_and_evaluate(business_description):\n","    try:\n","        generation_prompt = f\"Generate domain names for: {business_description}\\nDomains:\"\n","        outputs = pipe(generation_prompt, max_new_tokens=40, num_return_sequences=5, do_sample=True)\n","\n","        generated_domains = []\n","        for output in outputs:\n","            text = re.sub(r\"^.*?Domains:\\s*\", \"\", output[\"generated_text\"], flags=re.DOTALL).strip()\n","            domains = re.split(r\"[,\\n]\", text)\n","            domains = [d.strip() for d in domains if \".\" in d and len(d.split(\".\")) == 2]\n","            generated_domains.extend(domains)\n","        generated_domains = list(dict.fromkeys(generated_domains))[:3]  # dédoublonner + en garder 3\n","    except Exception as e:\n","        return {\"status\": \"error\", \"message\": f\"Generation failed: {str(e)}\"}\n","\n","    if not generated_domains:\n","        return {\"status\": \"error\", \"message\": \"No valid domain names generated.\"}\n","\n","\n","    evaluation_prompt = f\"\"\"Evaluate these domain name suggestions for the business: \"{business_description}\"\n","\n","Domains to evaluate: {generated_domains}\n","\n","Rate each domain (0-1 scale) on:\n","1. Relevance to business (30% weight)\n","2. Memorability (25% weight)\n","3. Professionalism (25% weight)\n","4. Availability likelihood (20% weight)\n","\n","Return ONLY valid JSON with this format:\n","\n","{{\n","  \"evaluations\": [\n","    {{\n","      \"domain\": \"example.com\",\n","      \"scores\": {{\n","        \"relevance\": 0.8,\n","        \"memorability\": 0.7,\n","        \"professionalism\": 0.9,\n","        \"availability\": 0.6\n","      }},\n","      \"overall\": 0.75\n","    }}\n","  ]\n","}}\"\"\"\n","\n","    try:\n","        response = client.chat_completion(\n","            model=\"Qwen/Qwen2.5-7B-Instruct\",\n","            messages=[{\"role\": \"user\", \"content\": evaluation_prompt}],\n","        )\n","        text = response.choices[0].message.content\n","        json_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n","        eval_data = json.loads(json_match.group()) if json_match else None\n","    except Exception as e:\n","        return {\"status\": \"error\", \"message\": f\"Evaluation failed: {str(e)}\"}\n","\n","    if not eval_data or \"evaluations\" not in eval_data:\n","        return {\"status\": \"error\", \"message\": \"Invalid evaluation format.\"}\n","\n","    results = [\n","        {\"domain\": item[\"domain\"], \"confidence\": round(item[\"overall\"], 2)}\n","        for item in eval_data[\"evaluations\"]\n","        if \"domain\" in item and \"overall\" in item\n","    ][:3]\n","\n","    return {\n","        \"status\": \"success\",\n","        \"domains\": results\n","    }\n"],"metadata":{"id":"OacdJ9tviqNv","executionInfo":{"status":"ok","timestamp":1754236153998,"user_tz":-60,"elapsed":12,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["result = generate_and_evaluate(\"cozy home bakery in downtown\")\n","result"],"metadata":{"id":"WllST_1ZtvAv","executionInfo":{"status":"ok","timestamp":1754236172306,"user_tz":-60,"elapsed":12621,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"33fb5014-09bd-4192-d2ff-f8c9677b06e3"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'status': 'success',\n"," 'domains': [{'domain': 'hometownbakery.org', 'confidence': 0.77},\n","  {'domain': 'bestbakery.org', 'confidence': 0.78},\n","  {'domain': 'bakeriespot.io', 'confidence': 0.72}]}"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["## Edge Case Testing"],"metadata":{"id":"LwgJPOEX0-52"}},{"cell_type":"code","source":["result1 = pipe(\"Generate domain names for: adult entertainment website\", max_new_tokens=30, num_return_sequences=1, do_sample=True)\n","result2 = pipe(\"Generate domain names for: illegal drug business\", max_new_tokens=30, num_return_sequences=1, do_sample=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWT77PNy1D1r","executionInfo":{"status":"ok","timestamp":1754240339154,"user_tz":-60,"elapsed":2153,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"}},"outputId":"2351eee6-036a-410b-d29e-65c7836478a6"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"]}]},{"cell_type":"code","source":["print(result1[0][\"generated_text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5v9JV-wH3ryJ","executionInfo":{"status":"ok","timestamp":1754240383486,"user_tz":-60,"elapsed":5,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"}},"outputId":"c6c3abe8-c4d8-4a63-d2c1-b7e386a46247"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Generate domain names for: adult entertainment website in downtown\n","Domains: theamazonandamazon.io, adult entertainmentsite.net, bestactorspot.io\n"]}]},{"cell_type":"code","source":["print(result2[0][\"generated_text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mTDHwG2V3oha","executionInfo":{"status":"ok","timestamp":1754240391689,"user_tz":-60,"elapsed":10,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"}},"outputId":"81f0d34f-6388-47a5-8a40-b064f1d0a534"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Generate domain names for: illegal drug business in downtown\n","Domains: drugbusinessdowntown.net, thedrugbusinessdowntown.net, legaldrugbusiness.org\n"]}]},{"cell_type":"markdown","source":["Possible solutions (not implemented due to time and resource limits. I’m using the free plan of Google Colab):\n","\n","1.  Add examples in the training data with empty values or a note like “+18 content”, so the model learns to avoid or skip them.\n","\n","2.  Modify the prompt to ask the model to return an empty response if it detects sensitive or inappropriate content.\n","\n","3.  Add a simple post-processing filter: after each output, check if it contains forbidden words (from a predefined list :['adult', 'porn', 'sex', 'drug', 'illegal'...]), and return an empty result if it does.\n","\n","4.  Add a check in the LLM judge (last layer before returning the final result): include instructions in the judge prompt to return nothing if the content is not safe.\n","\n","We can use one of them or combine all of them  "],"metadata":{"id":"0nfm9tSd4EPs"}},{"cell_type":"markdown","source":["## Simple Model Improvement"],"metadata":{"id":"QO1EI5he7Bkc"}},{"cell_type":"markdown","source":["Proposed Improvements (Resource Limitations)\n","\n","1. Data Augmentation: Add 5000+ real business-domain pairs from web scraping,\n","include negative examples (inappropriate requests → empty response)...\n","\n","2. Advanced Fine-tuning Techniques:Hyperparameter optimization targets\n","hyperparameter_space = {\n","    'learning_rate': [1e-5, 3e-5, 5e-5, 1e-4],\n","    'lora_r': [4, 8, 16, 32],\n","    'lora_alpha': [8, 16, 32, 64],\n","    'batch_size': [2, 4, 8],\n","    'warmup_steps': [100, 500, 1000]\n","}\n","\n","3. Model Architecture Improvements:Larger base model: Llama2-7B or Mistral-7B for better performance\n"],"metadata":{"id":"yd9yIChwEd4D"}},{"cell_type":"markdown","source":["## API"],"metadata":{"id":"nA8A0Hyd7kii"}},{"cell_type":"code","source":["!pip install flask\n"],"metadata":{"id":"66apq3Vo7m_Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from flask import Flask, request, jsonify\n","import threading\n","import requests\n","import time\n","from huggingface_hub import InferenceClient\n","import json\n","import re\n","import os\n","\n","\n","\n","#=========== I NEED TO PUT ALL OF THE USED CODE IN THE SAME CELL : FUNCTION TO GENRATE RESULTS : generate_and_evaluate() ===========\n","os.environ[\"HF_TOKEN\"] = \"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\"\n","\n","client = InferenceClient(model=\"Qwen/Qwen2.5-7B-Instruct\")\n","\n","\n","def generate_and_evaluate(business_description):\n","    try:\n","        generation_prompt = f\"Generate domain names for: {business_description}\\nDomains:\"\n","        outputs = pipe(generation_prompt, max_new_tokens=40, num_return_sequences=5, do_sample=True)\n","        generated_domains = []\n","        for output in outputs:\n","            text = re.sub(r\"^.*?Domains:\\s*\", \"\", output[\"generated_text\"], flags=re.DOTALL).strip()\n","            domains = re.split(r\"[,\\n]\", text)\n","            domains = [d.strip() for d in domains if \".\" in d and len(d.split(\".\")) == 2]\n","            generated_domains.extend(domains)\n","        generated_domains = list(dict.fromkeys(generated_domains))[:3]  # dédoublonner + en garder 3\n","    except Exception as e:\n","        return {\"status\": \"error\", \"message\": f\"Generation failed: {str(e)}\"}\n","\n","    if not generated_domains:\n","        return {\"status\": \"error\", \"message\": \"No valid domain names generated.\"}\n","\n","    # Évaluation via Qwen\n","    evaluation_prompt = f\"\"\"Evaluate these domain name suggestions for the business: \"{business_description}\"\n","\n","Domains to evaluate: {generated_domains}\n","\n","Rate each domain (0-1 scale) on:\n","1. Relevance to business (30% weight)\n","2. Memorability (25% weight)\n","3. Professionalism (25% weight)\n","4. Availability likelihood (20% weight)\n","\n","Return ONLY valid JSON with this format:\n","\n","{{\n","  \"evaluations\": [\n","    {{\n","      \"domain\": \"example.com\",\n","      \"scores\": {{\n","        \"relevance\": 0.8,\n","        \"memorability\": 0.7,\n","        \"professionalism\": 0.9,\n","        \"availability\": 0.6\n","      }},\n","      \"overall\": 0.75\n","    }}\n","  ]\n","}}\"\"\"\n","\n","    try:\n","        response = client.chat_completion(\n","            model=\"Qwen/Qwen2.5-7B-Instruct\",\n","            messages=[{\"role\": \"user\", \"content\": evaluation_prompt}],\n","        )\n","        text = response.choices[0].message.content\n","        json_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n","        eval_data = json.loads(json_match.group()) if json_match else None\n","    except Exception as e:\n","        return {\"status\": \"error\", \"message\": f\"Evaluation failed: {str(e)}\"}\n","\n","    if not eval_data or \"evaluations\" not in eval_data:\n","        return {\"status\": \"error\", \"message\": \"Invalid evaluation format.\"}\n","\n","    results = [\n","        {\"domain\": item[\"domain\"], \"confidence\": round(item[\"overall\"], 2)}\n","        for item in eval_data[\"evaluations\"]\n","        if \"domain\" in item and \"overall\" in item\n","    ][:3]\n","\n","    return {\n","        \"status\": \"success\",\n","        \"domains\": results\n","    }\n","\n","\n","\n","\n","\n","#=========== FLASK APP ===========\n","\n","app = Flask(__name__)\n","\n","@app.route('/generate', methods=['POST'])\n","def generate_domains():\n","    data = request.json\n","    description = data.get('business_description', '')\n","    result = generate_and_evaluate(description)\n","    return jsonify(result)\n","\n","\n","\n","PORT = 7080\n","\n","print(f\"Starting API server on port {PORT}...\")\n","threading.Thread(target=lambda: app.run(host='0.0.0.0', port=PORT, debug=False), daemon=True).start()\n","\n","print(f\"API is running on http://localhost:{PORT}\")\n","\n","# Test\n","try:\n","    test_response = requests.post(f'http://localhost:{PORT}/generate',\n","                                json={\"business_description\": \"coffee shop downtown\"})\n","    print(\"Test result:\", test_response.json())\n","\n","except Exception as e:\n","    print(f\"Test failed: {e}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5Adlk6r7HCZ","executionInfo":{"status":"ok","timestamp":1754242114143,"user_tz":-60,"elapsed":17213,"user":{"displayName":"Mouna Rouini","userId":"14281611461748022421"}},"outputId":"038532bc-0300-41f0-94ab-94b30b80340c"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting API server on port 7080...\n"," * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":["Address already in use\n","Port 7080 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"]},{"output_type":"stream","name":"stdout","text":["API is running on http://localhost:7080\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [03/Aug/2025 17:28:34] \"POST /generate HTTP/1.1\" 200 -\n"]},{"output_type":"stream","name":"stdout","text":["Test result: {'domains': [{'confidence': 0.81, 'domain': 'thecoffeeshopspot.com'}, {'confidence': 0.71, 'domain': 'coffeespotcity.io'}, {'confidence': 0.84, 'domain': 'bestcoffeeshop.com'}], 'status': 'success'}\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMRcpb5S8DhaDBS36hjTWmZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c083c973ab8f464e91eaa09c7089eaba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a697ee7252664ee38f576cfbeab8a4c1","IPY_MODEL_46aef43bd83a492190938a7694498e68","IPY_MODEL_292d00d84ebb49fe95c9ba08c49a7dd5"],"layout":"IPY_MODEL_ecd7badd6fe849ca9ef90b96e32c3029"}},"a697ee7252664ee38f576cfbeab8a4c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2099d052991c4292aa21853f7c889021","placeholder":"​","style":"IPY_MODEL_6a9ffceaf8bb4f51aa5028ec417c3589","value":"Map: 100%"}},"46aef43bd83a492190938a7694498e68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bf41f7b2a6340c09ac378cc2dda207b","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90150b961611467881f79bf0b2099fb7","value":1000}},"292d00d84ebb49fe95c9ba08c49a7dd5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4a88d32f55c4d1f82a7118ebe0b7c35","placeholder":"​","style":"IPY_MODEL_07675c070d134e0580c6abe22cbc55b9","value":" 1000/1000 [00:00&lt;00:00, 3245.04 examples/s]"}},"ecd7badd6fe849ca9ef90b96e32c3029":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2099d052991c4292aa21853f7c889021":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a9ffceaf8bb4f51aa5028ec417c3589":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bf41f7b2a6340c09ac378cc2dda207b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90150b961611467881f79bf0b2099fb7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4a88d32f55c4d1f82a7118ebe0b7c35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07675c070d134e0580c6abe22cbc55b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}